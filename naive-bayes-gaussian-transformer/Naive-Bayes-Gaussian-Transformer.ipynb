{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7e1e2c",
   "metadata": {},
   "source": [
    "### Naive Bayes using Gaussian Quantile Transformer\n",
    "This notebook implements Naive Bayes using a Gaussian Quantile Transformer from sklearn. \n",
    "\n",
    "This dataset is transformed using scaling functions from sklearn, specifically a Gaussian Quantile Transformer. This was a topic covered in machinelearningmastery.com and an offline ebook. I have covered Naive Bayes using Weka in my MSc course using a separate GUI application for Weka, so this lets me use it in Python with sklearn.\n",
    "\n",
    "Refer to below sklearn documentation for impact of scalers for input features.\n",
    "- https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
    "\n",
    "We import pandas, sklearn, train_test_split and the naive bayes GaussianNB library option.\n",
    "\n",
    "Note: Naive Bayes assumes the features are independent and do not interact. We know from applied statistics this is unlikely to be the case in real world datasets, but Naive Bayes is known to perform well in any case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbffb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a852d",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis\n",
    "We use the diabetes dataset. For information about this dataset, refer to the Kaggle dataset library summary:\n",
    "- https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "This will predicte whether a patient does or does not have diabetes. We have multiple predictor variables and one target variable - Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fcbbc5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m diabetes_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/diabetes.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/diabetes.csv'"
     ]
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv(\"../datasets/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba573db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29762223",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27277511",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7376d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .T at the end displays the transpose i.e. we flip the columns to be the rows and rows become the columns\n",
    "diabetes_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf5c152",
   "metadata": {},
   "source": [
    "Verify if any null values in the dataframe for a given data column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e285935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ac565",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d8176",
   "metadata": {},
   "source": [
    "The following calculates the pairwise correlation of columns. It does not include NA/null values.\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad661ce",
   "metadata": {},
   "source": [
    "Produce data visualization histogram plots for the pandas dataframe for the diabetes dataset and focus on the input feature distributions as we are going to scale the input data before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get histogram for each numeric variable - 9 variables so layout = 3x3\n",
    "features_including_output_label = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "diabetes_df[features_including_output_label].hist(bins=15, figsize=(15, 10), layout=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20ba04",
   "metadata": {},
   "source": [
    "##### Transform the dataset input features\n",
    "Transform the data input features. Import the QuantileTransformer. For more information, refer here:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html\n",
    "\n",
    "The goal of the Quantile Transformer is to transform the target dataset features and produce a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109782ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qt = QuantileTransformer(output_distribution='normal', n_quantiles=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627983e",
   "metadata": {},
   "source": [
    "Target specific columns for scaling - omitting \"Pregnancies\", based on data type considerations on Kaggle samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3366ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the original dataframe\n",
    "diabetes_df_scaled = diabetes_df\n",
    "diabetes_df_scaled[\"Age\"] = qt.fit_transform(diabetes_df[[\"Age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ad1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df_scaled[\"SkinThickness\"] = qt.fit_transform(diabetes_df[[\"SkinThickness\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaf1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df_scaled[\"Insulin\"] = qt.fit_transform(diabetes_df[[\"Insulin\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df_scaled[\"DiabetesPedigreeFunction\"] = qt.fit_transform(diabetes_df[[\"DiabetesPedigreeFunction\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632de929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get histogram for each numeric variable - 9 variables so layout = 3x3\n",
    "features_scaled = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "diabetes_df_scaled[features_scaled].hist(bins=15, figsize=(15, 10), layout=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859fed3d",
   "metadata": {},
   "source": [
    "Compare above scaled output with the previous default graphs for the dataset. You can see the histograms for the target feature columns now follow a normal distribution where they did not in the original default dataset prior to the transformation step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da958b",
   "metadata": {},
   "source": [
    "##### Create a train:test split on the dataset\n",
    "Next, we define our train:test split using sklearn library. This lets us defined our supervised learning training set and a holdout test data subset. We will use a 33% portion of the dataset as a test set. We will use this to test the accuracy of the ML model on data it has not seen before in training and if it has overfit during training or can generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into features and categorical predictor variable (0 or 1)\n",
    "X = diabetes_df_scaled.iloc[: , :8]\n",
    "y = diabetes_df_scaled.iloc[: , -1]\n",
    "\n",
    "# split into train and test sets with sklearn native train_test_split 33% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8502496",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925eaa9",
   "metadata": {},
   "source": [
    "##### Machine Learning Model and Training\n",
    "Now we create a GaussianNB machine learning model and fit it to our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94715f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_ml_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_ml_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412568f",
   "metadata": {},
   "source": [
    "##### Gaussian Naive Bayes Model using Transformed Data: Run Predictions, Evaluate Performance\n",
    "We now run the predictive analytics against the test dataset and calculate the accuracy of the ML model when predicting on new data, our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb_ml_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48094de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37996a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_ml_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c76bd2",
   "metadata": {},
   "source": [
    "Include the sklearn classification report for precision, recall, f1-score, and support metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = classification_report(y_test, y_pred, output_dict=False)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c899590",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c3e06",
   "metadata": {},
   "source": [
    "Below is a useful sklearn confusion matrix display utility plot. I always refer to it ever I need to check the array dimensions for true label, predicted labels. Seaborn is used later for an alternative display plot with text labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eff576",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70fce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion_matrix = pd.DataFrame(cm, ['True Non-Diabetes', 'True Diabetes'],\n",
    "                     ['Predicted No Diabetes', 'Predicted Diabetes'])\n",
    "\n",
    "sns.heatmap(df_confusion_matrix, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db003652",
   "metadata": {},
   "source": [
    "##### Gradio User Interface Layer\n",
    "In this section, we add a user interface layer. While we can create synthetic data functions in Python code to test the ML model, it helps for a human stakeholder to be able to test out a machine learning model in a web browser, especially when evaluating a prototype. This was a really nice utility demonstrated on the [serverless-ml MLOps](https://github.com/niallguerin/serverless-ml-course/tree/main/src/01-module) course.\n",
    "\n",
    "The below code re-uses the base code from serverless-ml GitHub course module 1 source code. However, this one is using a different dataset with more input values this time - diabetes and 8 input fields. I also modified the return output label and format to be a Text field not an Image result object so imports and code differs at those points below versus original template referenced.\n",
    "\n",
    "I have also modified it to include an additional input function to transform the input values as users would not enter transformed data formats, so the function transforms the data inputs to map to the type of transformations we performed on the ML model during training and testing so it gets data in a format it was trained on; otherwise it has a mismatch. \n",
    "\n",
    "The model only has about 75% accuracy and from the confusion matrix, we can see it's better at predicting True Negatives. Two test cases are included and we can see it does not generally give Expected Result for True Positive for test case 2, which it should, but this is expected given our evaluation metrics for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ec758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuses template code from the serverless-ml course to scaffold the gradio UI\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "def convert_label(label_num):\n",
    "    if(label_num == 0):\n",
    "        return \"Outcome: This patient does not have Diabetes.\"\n",
    "    if(label_num == 1):\n",
    "        return \"Outcome: This patient has Diabetes.\"\n",
    "\n",
    "def transform_input_sample(input_lst):\n",
    "    input_sample_df = pd.DataFrame(columns = X.columns)    \n",
    "    input_sample_df.loc[0] = input_lst\n",
    "    \n",
    "    # apply the quantile transformer to the input sample before calling the predictive analytics service\n",
    "    input_sample_df[\"SkinThickness\"] = qt.fit_transform(input_sample_df[[\"SkinThickness\"]])\n",
    "    input_sample_df[\"Insulin\"] = qt.fit_transform(input_sample_df[[\"Insulin\"]])\n",
    "    input_sample_df[\"DiabetesPedigreeFunction\"] = qt.fit_transform(input_sample_df[[\"DiabetesPedigreeFunction\"]])\n",
    "    input_sample_df[\"Age\"] = qt.fit_transform(input_sample_df[[\"Age\"]])\n",
    "\n",
    "    return input_sample_df\n",
    "    \n",
    "def diabetes(Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age):\n",
    "    input_list = []\n",
    "    input_list.append(Pregnancies)\n",
    "    input_list.append(Glucose)\n",
    "    input_list.append(BloodPressure)\n",
    "    input_list.append(SkinThickness)\n",
    "    input_list.append(Insulin)\n",
    "    input_list.append(BMI)\n",
    "    input_list.append(DiabetesPedigreeFunction)\n",
    "    input_list.append(Age)\n",
    "    \n",
    "    transformed_input_sample = transform_input_sample(input_list)    \n",
    "    result = gnb_ml_clf.predict(transformed_input_sample)\n",
    "    patient_status = convert_label(result)\n",
    "    \n",
    "    return patient_status\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=diabetes,\n",
    "    title=\"Diabetes Patient Predictive Analytics\",\n",
    "    description=\"Experiment with inputs to predict whether the patient has diabetes. Test Case 1: Expected Result: No Diabetes - [1,85,66,29,0,26.6,0.351,31], Test Case 2: Expected Result: Has Diabetes [6,148,72,35,0,33.6,0.627,50]\",\n",
    "    allow_flagging=\"never\",\n",
    "    inputs=[\n",
    "        gr.inputs.Number(default=1, label=\"Pregnancies\"),\n",
    "        gr.inputs.Number(default=85, label=\"Glucose\"),\n",
    "        gr.inputs.Number(default=66, label=\"BloodPressure\"),\n",
    "        gr.inputs.Number(default=29, label=\"SkinThickness\"),\n",
    "        gr.inputs.Number(default=0, label=\"Insulin\"),\n",
    "        gr.inputs.Number(default=26.6, label=\"BMI\"),\n",
    "        gr.inputs.Number(default=0.351, label=\"DiabetesPedigreeFunction\"),\n",
    "        gr.inputs.Number(default=31, label=\"Age\"),\n",
    "        ],\n",
    "    outputs=gr.Textbox(label=\"Outcome\"))\n",
    "\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a4215e",
   "metadata": {},
   "source": [
    "#### Web References\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "- https://gradio.app/docs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
